---
output:
  pdf_document:
    latex_engine: xelatex
classoption: notitlepage
header-includes:
  - "\\usepackage{graphicx}"
---

\begin{titlepage}
    \centering
    \vspace*{2cm}
    \includegraphics[width=0.6\textwidth]{UCT_Logo.jpg}\par
    \vspace{1cm}
    {\LARGE\bfseries Time Series, Assignment 1\par}
    \vspace{0.5cm}  
    \hrule  % 
    \vspace{0.5cm}  
    {\Large Petersen Trentin (PTRTRE004)
    \par}
    \vfill
    {\large \today\par}
\end{titlepage}

```{r setup, include=FALSE,warning=F,echo=FALSE}
knitr::opts_chunk$set(echo=TRUE,warning=F,message=F,echo=F,cache = T)
library(fpp3)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(forecast)
library(tseries)
library(fable)
library(patchwork)
library(rugarch)
library(knitr)
library(seasonal)
library(ggfortify)
library(quantmod)
```

# Abstract

Within this report are the findings and conclusions made for a project conducted for Eskom, with a strong focus on the forecasting of peak daily electricity demand and total energy lost due to unplanned outages (UCLF+OCLF). Using historical data from April 1, 2019 to September 13, 2023, a multitude of forecasting techniques and models were employed to produce valuable insights into the energy supply issues faced by South Africa. Thorough analysis of these forecasts by Eskom might enable the mitigation of load shedding and unplanned outages which will ultimately result in more stability in the national grid.

# Introduction

Over the past decade, the demand for electricity in South Africa has only increased which has proven itself to be a tough challenge for Eskom, South Africa's primary supplier of power. Unplanned outages caused by ageing infrastructure and poor management combined with the sharp fluctuations in the demand for electricity result in hindrances in meeting the energy demands of South Africa as well as causing alarming rates of instability in the national power grid. This has led to an increase of the amount of load shedding hours in South Africa, even reaching a new record of consecutive days of load shedding in 2023 which had a detrimental impact on the economy of South Africa and the lives of many people. The aim of this project is to produce robust forecasts for the peak daily electricity demand as well as the proportion of energy lost due to all unplanned outages.The robust forecasting of these metrics is vital to Eskom's success in reducing the frequency of load shedding and improving the stability and reliability of the national grid.

The data which will be analysed and then used to create forecasts is named 'ESK6816.csv' and is provided by Eskom. The dataset contains hourly observations beginning $01/04/2019\quad-\quad00:00$ and ending $31/03/2024\quad-\quad23:00$. For the sake of the analysis and forecasting there are two primary variables of interest, $RSA.Contracted.Demand$ and $Total.UCLF.OCLF$. $RSA.Contracted.Demand$ represents the hourly average demand that Eskom must fulfill. $Total.UCLF.OCLF$ represents the total proportion of Eskom's plant capacity that unavailable due to unplanned outages. 

# Questions/Hypotheses

Eskom states that there are two peak electricity demand periods within a day: 6am to 9am and 5pm to 9pm, the focus of this report will be on the latter. During this period of the day is when most households in South Africa use appliances such as electric stoves, heaters and entertainment devices; at the same time there may also still be some commercial or industrial activities which overlap with this increased household demand. This spike in electricity demand, puts a lot of strain on the grid and the ageing infrastructure.

It is hypothesized that the seasons of the year as well as the economic activity will have a large impact on the daily peak demand, causing an annual pattern to emerge, with demand peaking in winter and reaching a minimum in summer. A weekly pattern is also expected as during the work week, Monday to Friday, the demand will go up and on the weekends the demand will greatly reduce. These predictable seasonal patterns should assist with producing robust forecasts.

Producing robust forecasts for the energy loss due to the unplanned outages will be more of a challenge as it depends on factors such as the availability of funds and skilled personnel to maintain the ageing infrastructure and water availability for the cooling of the large number of coal power plants. A slight upward trend in the energy loss due to unplanned outages is expected due to ageing infrastructure. 

Using the forecasts, some critical questions might be answered. For instance, how can load shedding as well as unplanned outage frequency be minimized during the peak demand period 5pm - 9pm? Additionally how can electricity pricing and contract negotiation be optimized to best mimic the patterns in the peak daily demand which will help reduce operational costs.

The forecasts produced will be a blend of short-term and medium-term forecasts which will be used to support operational decisions, grid management and resource allocation for maintanence and power generation.

# Section 1 - EDA

## 1.1 - Data and variable names/classes

```{r}
esk_data=tibble(read.csv("ESK6816.csv"))
names(esk_data)[1]="Date"
variable_names=(colnames(esk_data))

esk_data$Date.Time=as.POSIXct(esk_data$Date, format="%Y/%m/%d %H:%M")
# esk_data|>filter(Date.Time>="2020-12-01" & Date.Time<="2020-12-31")
esk_data=esk_data|>filter(format(Date.Time, "%H") >= 17 & format(Date.Time, "%H") <= 21)#Explain that we want to model the peak demand during high demand periods
esk_data$Date=as.Date(esk_data$Date)

```

The data is read in from the ESK6816.csv dataset. The raw data consists of 22 variables and 43848 observations. Of the 22 variables we are only interested in the $Date$, $RSA.Contracted.Demand$, $RSA.Contracted.Forecast$ and $Total.UCLF.OCLF$.

```{r}
#Appendix
# variables=matrix(c("Date","Date","RSA.Contracted.Demand","numeric","RSA.Contracted.Forecast","numeric","Total.UCLF.OCLF","numeric"),ncol=2,byrow=T)
# 
# colnames(variables)=c("Variable Name","Variable Type")
# kable(variables,row.names = F,caption="The variables of the ESK6816 dataset and their variable types.")
```


A POSIXct, $Date.Time$, variable is created and then filtered to only include the hourly observations from 5pm-9pm, the peak demand period. The table below presents a some summary statistics of the data for the two variables of interest - $RSA.Contracted.Demand$ and $Total.UCLF.OCLF$.

## 1.2 - Summary statisitcs and Missing Observations

```{r}
dem_5ns=t(as.matrix(summary(esk_data$RSA.Contracted.Demand)))
out_5ns=t(as.matrix(summary(esk_data$Total.UCLF.OCLF)))

num_sums = rbind(dem_5ns,out_5ns)
rownames(num_sums)=c("Demand","Energy Loss")
kable(num_sums,caption="Summary statistics - RSA.Contracted.Demand & Total.UCLF.OCLF")
```

<!-- These statistics are better contextualized by additionally plotting a histogram for each variable as shown below. For the demand variable we can see that it is slightly skewed to the left and appears to be almost bi-modal with the mean falling in between the two peaks. The plot of the Energy loss is mostly symmetrical, somewhat multimodal and slightly skewed to the right. These features will be investigated further in the time plots of the variables. -->

```{r,fig.height=3.5}
# hist1=ggplot(esk_data, aes(x = RSA.Contracted.Demand)) +
#   geom_histogram(binwidth = 100, fill = "blue", color = "black", alpha = 0.7) +
#   labs(title = "Histogram of RSA Contracted Demand",
#        x = "RSA Contracted Demand",
#        y = "Frequency") +
#   theme_minimal()
# 
# hist2=ggplot(esk_data, aes(x = Total.UCLF.OCLF)) +
#   geom_histogram(binwidth = 100, fill = "red", color = "black", alpha = 0.7) +
#   labs(title = "Histogram of Total Energy Loss",
#        x = "UCLF+OCLF",
#        y = "Frequency") +
#   theme_minimal()
# 
# hist_grid = hist1/hist2
# hist_grid
```


Table X shows that there are 1000 NA observations, on inspection the data shows that from the 14th of September onwards the datasets only contains values for the $Date$ and $RSA.Contracted.Forecast$ variables. The choice was made to truncate the data such that the final observation in the dataset had the Date and time: $2023/09/13 - 21:00$. The dataset contained no other missing data.

```{r}
missing_data_inds=(which(is.na(esk_data["RSA.Contracted.Demand"])))
df1 = head(esk_data[missing_data_inds,1:3],2)
df2 = tail(esk_data[missing_data_inds,1:3],2)

kable(rbind(df1, df2),caption = "The first and last two observations with missing data.")

```

## 1.3 - Plotting the raw data

We can now plot our data for both the $RSA.Contracted.Demand$ and $Total.UCLF.OCLF$ variables using time plots as shown below. MA-720 (Monthly) smoothing was applied to expose the trend within the raw data.

```{r,fig.height=2,fig.width=8,fig.cap="Time plot of the raw demand data.",fig.pos='!h'}
raw_data=esk_data|>as_tsibble(index=Date.Time)
esk_data_ma_720=raw_data|>mutate(
`720-MA`=slider::slide_dbl(RSA.Contracted.Demand, mean,
.before=720, .after=720, .complete=TRUE))



dem_ma=raw_data|>autoplot(RSA.Contracted.Demand,color="black")+
              xlab("Time")+
              autolayer(esk_data_ma_720,vars(`720-MA`),color="red")

esk_out_data_ma_720=raw_data|>mutate(
`720-MA`=slider::slide_dbl(Total.UCLF.OCLF, mean,
.before=720, .after=720, .complete=TRUE))



out_ma=raw_data|>autoplot(Total.UCLF.OCLF,color="black")+
              xlab("Time")+
              autolayer(esk_out_data_ma_720,vars(`720-MA`),color="red")

dem_ma
```

The figure shows that there is some annual seasonality/cyclicality in the demand data. This can be logically explained with the seasons of the year and their correlation with electricity demand. In summer the demand is lower, then it increases until it peaks in mid-winter when the days are shorter and colder, requiring more electricity for lighting and heating. Every year there is also a sharp decline in December/January, we will investigate this further in Section 1.5. The demand time plot also shows the dramatic effect that Covid had on the demand in 2020 making it an outlier amongst the other 4 years (2019,2021,2022,2023).

The demand time plot has no clear trend and the variance appears to be fairly constant (although quite high) with the exception of the Covid era and the December/Christmas period.

```{r,fig.height=2,fig.width=8,fig.cap="Time plot of the raw energy loss data.",fig.pos='!h'}
out_ma
```

The time plot for the total energy lost due to unplanned outages presents quite a clear positive linear trend but lacks any noticeable seasonality. The variance also appears to be constant for the majority of the time. We notice that there doesn't seem to be much correlation between the demand and the energy lost due to unplanned outages with the exception of the Covid era. The increasing energy loss can likely be attributed to the lack of adequate infrastructure maintenance.

## 1.4 - Examining major decreases in December

It was mentioned in section 1.4 that there appeared to be a drastic decrease in the demand around December/January every year. The time plot in the Appendix shows that the sharp decrease is due to Christmas and New years celebrations/holidays. During these times businesses will often close or scale down as people take leave. Another contributor is the people that leave the country to go on holiday, however the impact of this might be cancelled out by tourists visiting South Africa during that period. 
```{r,fig.height=2}
#Appendix
# raw_data|>filter(Date>="2022-12-19",Date<="2023-01-05")|>autoplot(RSA.Contracted.Demand)+ylab("Peak Demand")+xlab("Time")
```



## 1.5 - Data Cleaning

```{r,fig.height=2.5}
# data_2020=esk_data|>filter(format(Date.Time, "%Y") == 2020)|>as_tsibble(index=Date.Time)
# dem_2020=autoplot(data_2020,RSA.Contracted.Demand)+xlab("Time")+ylab("Hourly Electricity Demand")+ggtitle("2020") #Already thinking of truncating from september because of NA data
#                                                                                       #Because of covid we remove start data at 14 sept. cuz data ends at 13 sept.
# out_2020=autoplot(data_2020,Total.UCLF.OCLF)+xlab("Time")+ylab("UCLF + OCLF") 
# 
# data_2021=esk_data|>filter(format(Date.Time, "%Y") == 2021)|>as_tsibble(index=Date.Time)
# dem_2021=autoplot(data_2021,RSA.Contracted.Demand)+xlab("Time")+ylab("Hourly Electricity Demand")+ggtitle("2021")
# out_2021=autoplot(data_2021,Total.UCLF.OCLF)+xlab("Time")+ylab("UCLF + OCLF") 
# data_2021=esk_data|>filter(format(Date.Time, "%Y") == 2021)|>as_tsibble(index=Date.Time)
# 
# data_2022=esk_data|>filter(format(Date.Time, "%Y") == 2022)|>as_tsibble(index=Date.Time) #We can see that beginning the data in sept. 2020 is also adequate as
# dem_2022=autoplot(data_2022,RSA.Contracted.Demand)+xlab("Time")+ylab("Hourly Electricity Demand")#   the pattern matches that of 2022 where things had stabilised.
# out_2022=autoplot(data_2022,Total.UCLF.OCLF)+xlab("Time")+ylab("UCLF + OCLF") #Already thinking of truncating from september because of NA data
# 
# data_2023=esk_data|>filter(format(Date.Time, "%Y") == 2023)|>as_tsibble(index=Date.Time)
# dem_2023=autoplot(data_2023,RSA.Contracted.Demand)+xlab("Time")+ylab("Hourly Electricity Demand")
# out_2023=autoplot(data_2023,Total.UCLF.OCLF)+xlab("Time")+ylab("UCLF + OCLF") 
# 
# dem_plots=(dem_2020 | dem_2021)
# out_plots=(out_2020 | out_2021) / (out_2022 | out_2023)
# 
# dem_plots
```

Figure X shows how the demand in 2020 differed from the years 2019 and 2021-2023. Events such as the Covid pandemic are irregular occurrences and thus it is sensible to truncate the data such as to not include demand data which was greatly affected by the Covid pandemic. By comparing 2020 to 2021, it appears that by July 2020 the seasonal pattern seemed to have stabilized , therefore a choice was to truncate the data such that it begins in September of 2020 which will give us 4 full years of data. Thus observations in the final cleaned demand data will begin $2020/09/14 - 17:00$ and run until $2023/09/13 - 21:00$.

```{r,fig.height=3}
# out_plots
```

Much like for the demand data the effect of the Covid pandemic is reflected in the energy loss data. However unlike for demand data, there is no clear annual pattern or predictable trend for energy loss due to unplanned generation outages. This is most likely because it depends on current circumstances such as infrastructure failures, maintenance issues or other events that might affect generation capacity. Thus for forecasting unplanned outages, the data that should be used should be recent.

Therefore the data is truncated to include only a single year and will run from $2022/09/14$ to $2023/09/13$.

```{r}
esk_data_dem=esk_data|>filter(Date.Time>="2020-09-14" & Date.Time<="2023-09-14")
esk_data_out=esk_data|>filter(Date.Time>="2022-09-14" & Date.Time<="2023-09-14")
```

## 1.6 - Aggregating data

(*UNFINISHED*) In order to convert the hourly demand data into daily data such that the peak daily demand can be forecasted, the hourly data will be aggregated by taking the maximum demand of the 5pm-9pm period each day.

```{r}
#Peak daily demand (Max of the evening period 17:00 - 21:00)
elec_demand=esk_data_dem|>group_by(Date)|>summarise(peak_demand=max(RSA.Contracted.Demand),fc=max(RSA.Contracted.Forecast))

#Get associated forecast for that max demand
esk_forecasts=esk_data_dem|>group_by(Date)|>
  filter(RSA.Contracted.Demand == max(RSA.Contracted.Demand))|>
  select(Date,RSA.Contracted.Forecast)|>ungroup()|>as_tsibble(index = Date)

elec_demand=elec_demand|>select(Date,peak_demand)|>as_tsibble(index=Date)|>na.omit()
gen_out=esk_data_out|>group_by(Date)|>summarise(unplanned_outages=mean(Total.UCLF.OCLF))|>as_tsibble(index=Date)|>na.omit()
```

## 1.7 - Decomposition of data

```{r,fig.height=3,fig.cap="Time plots of cleaned/transformed data with trend plots"}
elec_plot=autoplot(elec_demand)+xlab("Time")+ylab("Peak Demand")+ggtitle("Time plot for Peak Demand")
gen_plot=autoplot(gen_out)+xlab("Time")+ylab("UCLF+OCLF")+ggtitle("Time plot for UCLF+OCLF")
dem_trend=elec_demand |>model(STL(peak_demand~trend()))|>
  components() |>
  autoplot(trend)+ggtitle("Trend for Peak Demand")

gen_trend=gen_out |>model(STL(unplanned_outages~trend()))|>
  components() |>
  autoplot(trend)+ggtitle("Trend for UCLF+OCLF")

time_trend = (elec_plot|dem_trend) / (gen_plot | gen_trend)
time_trend
```

The figure above shows that there is some non-linear trend in the peak demand data  but no clear trend in the data for energy loss due to unplanned outages.




```{r,fig.height=3,fig.cap="Weekly and annual seasonality of cleaned/transformed data."}
#Weekly seasonality -- Peaks on weekends
may_data=elec_demand |>
  filter(format(Date, "%m") == "05") |>
  mutate(Year=as.integer(format(Date, "%Y")),Day=as.integer(format(Date,"%d"))) |>
  as_tsibble(index=Day, key=Year)
may_dem=autoplot(may_data,peak_demand)+ylab("Peak Demand")+ggtitle("Peak daily demand May")+xlab("Time")

may_out_data=gen_out |>
  filter(format(Date, "%m") == "05") |>
  mutate(Year=as.integer(format(Date, "%Y")),Day=as.integer(format(Date,"%d"))) |>
  as_tsibble(index=Day, key=Year)
may_out=autoplot(may_out_data,unplanned_outages)+ylab("UCLF+OCLF")+ggtitle("UCLF+OCLF for May 2022")+xlab("Time")

annual_seasonality = gg_season(elec_demand)+ylab("Peak Daily Demand") 
trendseason_grid = (may_dem|may_out)/annual_seasonality
trendseason_grid
```


The figure shows that there is strong weekly seasonality in the peak daily demand data which is consistent across 2021-2023. There does not appear to be any weekly seasonality for the energy loss data.

There is clear annual seasonality pattern for the daily peak demand data. Because we are only using a single year of data for the energy loss, it is not sensible to plot the annual seasonality.


(*UNFINISHED*)

```{r,fig.height=3.5,fig.cap="ACF and PACF plots of Peak Daily Demand Data."}

dem_acf_norm=autoplot(acf(elec_demand, plot = FALSE)) +
  labs(title = "Peak Daily Demand - ACF",
       x = "Lag",
       y = "ACF") +
    geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  scale_x_continuous(
    breaks = c(0, 1, 2,3,4),  # Custom x-axis breaks
    labels = c("0", "7","14", "21","28")  # Custom x-axis labels
  ) 

dem_pacf_norm=autoplot(pacf(elec_demand, plot = FALSE)) +
  labs(title = "Autocorrelation Function (ACF)",
       x = "Lag",
       y = "PACF") +
    geom_hline(yintercept = 0, linetype = "solid", color = "black") +
   scale_x_continuous(
    breaks = c(0, 1, 2,3,4),  # Custom x-axis breaks
    labels = c("0", "7","14", "21","28")  # Custom x-axis labels
  )

dem_acf_365=autoplot(acf(elec_demand,lag.max = 365, plot = FALSE)) +
  labs(title = "Autocorrelation Function (ACF)",
       x = "Lag",
       y = "ACF") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  scale_x_continuous(
    breaks = c(0, 15, 30,45),  # Custom x-axis breaks
    labels = c("0", "100","200", "300")  # Custom x-axis labels
  ) 

dem_pacf_365=autoplot(pacf(elec_demand,lag.max = 365, plot = FALSE)) +
  labs(title = "Autocorrelation Function (ACF)",
       x = "Lag",
       y = "PACF") +
    geom_hline(yintercept = 0, linetype = "solid", color = "black") +
   scale_x_continuous(
    breaks = c(0, 15, 30,45),  # Custom x-axis breaks
    labels = c("0", "100","200", "300")  # Custom x-axis labels
  )

dem_ac_grid = (dem_acf_norm | dem_pacf_norm) / (dem_acf_365|dem_pacf_365)
dem_ac_grid
```

Figure X shows significant autocorrelation in the series up to relatively high lags in both the PACF and ACF. There are clear spikes in autocorrelation every 7 lags in both the ACF and PACF which represent the strong weekly seasonality discussed in Section 1.8.2. The figure also suggests that there is some trend in the data through the decaying pattern of the autocorrelation in the ACF, this happens as if there is trend then observations that are close to each other in time are close in size. 

The cyclicality in the ACF is representative of the annual seasonality/cyclicality in the peak daily demand data. From the ACF plot as well as the supporting time plots we can infer that the annual period is roughly 365 days. Using Figure X and the figure above we it is clear due due to the presence of trend and strong seasonality that the Peak Demand data is non-stationary.

```{r}
#ACF AND PACF for GEN_OUT
```



# Section 2 - Peak Daily Demand Model Fitting

For the purpose of the model fitting, forecasting and comparison, the data will be split up into training/test sets. The forecast horizon was set to 92 days (3 months), a decision which was based on the aims of the project which include producing short-term forecasts which will be used in handling load shedding and medium-term forecasts which will be used in grid management decisions. A forecast horizon of 3 months will also show if the models are accurately capturing the annual seasonal pattern in the data. Therefore, the training set will consist of all observations from $2020/09/14$ to $2023/06/13$ and the test set will be made up of the last 3 months from $2023/06/14$ to $2023/09/14$.


```{r}
train = elec_demand|>filter(Date<="2023/06/14")
test = elec_demand|>filter(Date>="2023/06/14")
```

## 2.1 Differencing for Non-seasonal Models

Figure X shows that the peak daily demand data is clearly non-stationary as the series does not fluctuate around a mean of zero and there is a clear presence of seasonality which is supported by the ACF plot in Figure X. Therefore for the non-seasonal models (AR, MA, ARMA and ARIMA) we can take first differences until the data appears stationary.

```{r,fig.height=2.5,fig.cap="Differenced data and ACF/PACF plots (Non-seasonal)."}
#Taking differences
elec_demand$diffed=difference((elec_demand$peak_demand),lag=1,differences=1) 
gg_tsdisplay(elec_demand,diffed, plot_type='partial')
```

The figure above shows data that is representative of stationary series as it fluctuates around a zero-mean and displays no heteroskedasticity.

We can then perform an Augmented Dickey-Fuller test, to test for the presence of a unit root in the series. The null hypothesis of the test is as follows $H_0:$ There is a unit root present in the series, i.e., the series is non-stationary. And the alternative hypothesis is $H_1:$ There is no unit root present in the series, i.e., the series is stationary.

```{r}
adftest=adf.test(na.omit(elec_demand$diffed),alternative="stationary") #p-val=0.01 therefore, reject null that time series is non-stationary
df = data.frame(Statistic=adftest$statistic,P.Value=adftest$p.value,Alternative=adftest$alternative)
kable(df,row.names = F,caption = "ADF Test Results")
```

As shown in the table above, the p-value of the ADF test is $p=0.01$, this means that there is sufficient evidence to reject the null hypothesis. Thus we can conclude that the series is stationary.




## 2.2 AR/MA/ARMA/ARIMA (Non-seasonal) Models

To begin, simple model autoregressive, moving-average, ARMA and ARIMA models will be developed, these are relatively straight forward to fit however, given the seasonality present in the data as shown in Section 1.8.2, we expect that AR, MA, ARMA and ARIMA models will not fit the data adequately. This is because they do not take the seasonal components of the data into consideration, this will result in poor quality forecasts and residuals which indicate that  there is information in the series which has not been captured by the model. For the sake of comprehensiveness and providing a baseline, non-seasonal models are included in the analysis.

Because of the theoretical limitations of the non-seasonal models, the model fitting and selection process was drastically simplified, leaving the focus on the seasonal models/methods. The non-seasonal models were fit using the same simple methodology:

\begin{enumerate}
\item Inspect the ACF and PACF plots of the stationarized data in Section 1.9.1.
\item Determine the relevant orders for $p,d$ and $q$ for a candidate model.
\item Fit multiple models by varying the relevant orders such as $p=5,6,7,8$ for an $AR(p)$ model.
\item Choose the best model by comparing AICc values. (Appendix)
\end{enumerate}




```{r}
#In the general context of this problem, fitting an AR(p) does not make any sense as there is seasonality in the data and the PACF tapers off slowly whilst the ACF spikes and decreases, therefore even though there is seasonality, an MA(q) model already makes more sense.
ar_models=train|>model(

  `AR(5)`=ARIMA(peak_demand ~0+pdq(5,1,0)+PDQ(0,0,0)),
  `AR(6)`=ARIMA(peak_demand ~0+pdq(6,1,0)+PDQ(0,0,0)),
 `AR(7)`=ARIMA(peak_demand ~0+pdq(7,1,0)+PDQ(0,0,0)),
  `AR(8)`=ARIMA(peak_demand ~0+pdq(8,1,0)+PDQ(0,0,0))
  )
aicc_table=ar_models|>
                  glance() |>
                      select(.model, AICc)

ar_aic_tbl=kable(aicc_table,col.names = c("Model","AICc"),caption="AICc for different AR(p) models.")


```

```{r}
selected_ar_model=ar_models |> select(`AR(8)`)
#gg_tsdisplay(residuals(selected_ar_model),plot_type = "partial")
#Forecasting
ar_forecasts=selected_ar_model|>forecast(h="92 days")
ar_acc=accuracy(ar_forecasts$.mean,test$peak_demand)

ar_fc_plot=ar_forecasts|>autoplot(train)+ylab("Peak Demand")+xlab("Time")+ggtitle("AR(8)")
ar_lb_test=augment(selected_ar_model)|>features(.resid, ljung_box, lag=14, dof =6)
```

```{r}
ma_models=train|>model(
  `MA(4)`=ARIMA(peak_demand ~0+pdq(0,1,4)+PDQ(0,0,0)),
  `MA(5)`=ARIMA(peak_demand ~0+pdq(0,1,5)+PDQ(0,0,0)),
  `MA(6)`=ARIMA(peak_demand ~0+pdq(0,1,6)+PDQ(0,0,0)),
  `MA(7)`=ARIMA(peak_demand ~0+pdq(0,1,7)+PDQ(0,0,0))
  
  )

aicc_table=ma_models|>
                  glance() |>
                      select(.model, AICc)

ma_aic_tbl=kable(aicc_table,col.names = c("Model","AICc"),caption="AICc for different MA(q) models.")
```

```{r}
ma_selected_model=ma_models |> select(`MA(7)`)
#gg_tsdisplay(residuals(ma_selected_model),plot_type = "partial")

#
# #Forecasting
ma_forecasts=ma_selected_model|>forecast(h="92 days")
ma_acc=accuracy(ma_forecasts$.mean,test$peak_demand)

ma_fc_plot=ma_forecasts|>autoplot(train)+ylab("Peak Demand")+xlab("Time")+guides(fill = "none")+ggtitle("MA(7)")
ma_lb_test=augment(ma_selected_model)|>features(.resid, ljung_box, lag=14, dof =7)

```

```{r}
#ARMA Models
arma_models= train|>model(
  `ARMA(4,4)`=ARIMA(peak_demand ~0+pdq(4,1,4)+PDQ(0,0,0)),
  `ARMA(4,5)`=ARIMA(peak_demand ~0+pdq(4,1,5)+PDQ(0,0,0)),
  `ARMA(5,4)`=ARIMA(peak_demand ~0+pdq(5,1,4)+PDQ(0,0,0)),
  `ARMA(5,5)`=ARIMA(peak_demand ~0+pdq(5,1,5)+PDQ(0,0,0)),
  `ARMA(5,6)`=ARIMA(peak_demand ~0+pdq(5,1,6)+PDQ(0,0,0)),
  `ARMA(5,7)`=ARIMA(peak_demand ~0+pdq(5,1,7)+PDQ(0,0,0))
  
  )
aicc_table=arma_models|>
                  glance() |>
                      select(.model, AICc)
arma_aic_tbl=kable(aicc_table,col.names = c("Model","AICc"),caption="AICc for different ARMA(p,q) models.")
```

```{r}
arma_selected_model=arma_models |> select(`ARMA(5,6)`)
#gg_tsdisplay(residuals(arma_selected_model),plot_type = "partial")
 
#Forecasting
arma_forecasts=arma_selected_model|>forecast(h="92 days")
arma_acc=accuracy(arma_forecasts$.mean,test$peak_demand)
arma_fc_plot=arma_forecasts|>autoplot(train)+ylab("Peak Demand")+xlab("Time")+guides(fill = "none")+ggtitle("ARMA(5,6)")
arma_lb_test=augment(arma_selected_model)|>features(.resid, ljung_box, lag=14, dof =3)

```

```{r}
#ARIMA Models
# auto.arima(train[,c(-3,-4)],seasonal = F,stepwise = T)
arima_models= train|>model(
  `ARIMA(3,1,3)`=ARIMA(peak_demand ~0+pdq(3,1,3)+PDQ(0,0,0)),
  `ARIMA(3,1,4)`=ARIMA(peak_demand ~0+pdq(3,1,4)+PDQ(0,0,0)),
  `ARIMA(3,1,5)`=ARIMA(peak_demand ~0+pdq(3,1,5)+PDQ(0,0,0)),
  `ARIMA(4,1,3)`=ARIMA(peak_demand ~0+pdq(4,1,3)+PDQ(0,0,0)),
  `ARIMA(4,1,4)`=ARIMA(peak_demand ~0+pdq(4,1,4)+PDQ(0,0,0)),
  `ARIMA(4,1,5)`=ARIMA(peak_demand ~0+pdq(4,1,5)+PDQ(0,0,0)),
  `ARIMA(5,1,3)`=ARIMA(peak_demand ~0+pdq(5,1,3)+PDQ(0,0,0)),
  `ARIMA(5,1,4)`=ARIMA(peak_demand ~0+pdq(5,1,4)+PDQ(0,0,0)),
  `ARIMA(5,1,5)`=ARIMA(peak_demand ~0+pdq(5,1,5)+PDQ(0,0,0))
  )
aicc_table=arima_models|>
                  glance() |>
                      select(.model, AICc)

arima_aic_tbl=kable(aicc_table,col.names = c("Model","AICc"),caption="AICc for different AR(p) models.")
arima_selected_model=arima_models |> select(`ARIMA(5,1,4)`)
```

```{r}

# gg_tsdisplay(residuals(arima_selected_model),plot_type = "partial")

# #Forecasting
 arima_fc=arima_selected_model|>forecast(h="92 days")
 arima_fc_plot=arima_fc|>autoplot(train)+xlab("Time")+ylab("Peak Demand")+guides(fill = "none")+ggtitle("ARIMA(5,1,4)")
 arima_acc = accuracy(arima_fc$.mean,test$peak_demand)

arima_lb_test=augment(arima_selected_model)|>features(.resid, ljung_box, lag=14, dof =5)
```

```{r}
model_specs_df=t(data.frame(Specification=c("AR(8)","MA(7)","ARMA(5,6)","ARIMA(5,1,4)")))
colnames(model_specs_df)=NULL
rownames(model_specs_df)=NULL
kable(model_specs_df,caption = "Best model specifications chosen using AICc.")
```


A residual analysis was conducted on the models listed above. This was comprised of interpreting the plots of the residuals (Appendix) and the results of the Ljung-Box test for autocorrelation of the residuals.

The hypotheses for the Ljung-Box test are as follows:

$H_0:$ There is no autocorrelation in the residuals for a fixed number of lags (*REF*).

$H_1:$ There is autocorrelation present in the residuals at some lag/s $l$ in the residuals. 

```{r}
lb_test_df = rbind(ar_lb_test,ma_lb_test,arma_lb_test,arima_lb_test)
colnames(lb_test_df)=c("Model","Test Statistic","P Value")
lb_test_df$`AC Present (Y/N)`=c("Y","Y","Y","Y") 
lb_test_df$`First Significant AC at Lag` = c("7","6","2","5")
kable(lb_test_df,caption="Ljung-Box Test Results")
```

The Ljung-Box test results above and the plots in the Appendix confirm the expectation that AR, MA, ARMA and ARIMA models will not be appropriate for modelling the given series as all models display significant autocorrelation in the residuals which indicates that there is information that the models are failing to capture. All of the non-seasonal models showed significant autocorrelation at lag 7 which indicates that the strong weekly seasonality was not captured by the models and was still present in the series.
Hence the forecast plots are not closely analyzed as the non-seasonal models are inadequate for modelling this series, however, the plots can be found in the Appendix.

```{r,fig.height=6,fig.width=10}
#Appendix
# fc_grid = (ar_fc_plot | ma_fc_plot) / (arma_fc_plot | arima_fc_plot)
# fc_grid 
```



## 2.3 Differencing for Seasonal Models

As mentioned in Section 1.9.1, Figure X shows that the peak daily demand data is clearly non-stationary. From the investigation into the seasonality present in the data in Section 1.8.3, it is evident that there is strong weekly seasonality in the data which suggests the use of a model such as a SARIMA which takes into account the seasonal components of a series. Seasonal differencing ($m=7$) was applied.

```{r,fig.height=1.5,fig.cap="Differenced data (Seasonal)"}
elec_demand$seas_diffed=difference(elec_demand$peak_demand,lag=7,differences=1)
seas_diffed_plot=autoplot(elec_demand,seas_diffed)+xlab("Time")+ylab("SeasDiff(Peak Demand)")
elec_demand$seas_diffed=difference(elec_demand$seas_diffed,lag=1,differences=1)
diff_seas_diffed_plot=autoplot(elec_demand,seas_diffed)+xlab("Time")+ylab("Diff(SeasDiff(Peak Demand))")

diff_plot = seas_diffed_plot | diff_seas_diffed_plot
diff_plot
```

The plot below shows that the data still somewhat exhibits the annual seasonal pattern, therefore a first difference will also be applied to the series. The seasonally and first differenced is shown in the figure below. The series appears to have been stationarized.

```{r,fig.height=1.5,fig.cap="ACF/PACF of seasonal and first Differenced data."}
seas_acf=autoplot(acf(na.omit(elec_demand$seas_diffed), plot = FALSE)) +
  labs(
       x = "Lag",
       y = "acf") +
    geom_hline(yintercept = 0, linetype = "solid", color = "black") +
    scale_x_continuous(
    breaks = c(0, 7, 14,21,28),  # Custom x-axis breaks
    labels = c("0", "7","14", "21","28")  # Custom x-axis labels
  )

seas_pacf=autoplot(pacf(na.omit(elec_demand$seas_diffed), plot = FALSE)) +
  labs(
       x = "Lag",
       y = "pacf") +
    geom_hline(yintercept = 0, linetype = "solid", color = "black") +
    scale_x_continuous(
    breaks = c(0, 7, 14,21,28),  # Custom x-axis breaks
    labels = c("0", "7","14", "21","28")  # Custom x-axis labels
  )
seas_acf_pacf_grid=seas_acf | seas_pacf
seas_acf_pacf_grid
```

Once again an ADF test can be performed to determine if the differenced series has reached stationarity. $H_0:$ There is a unit root present in the series, i.e., the series is non-stationary. $H_1:$ There is no unit root present in the series, i.e., the series is stationary.

```{r}
adftest=adf.test(na.omit(elec_demand$seas_diffed),alternative="stationary") #p-val=0.01 therefore, reject null that time series is non-stationary
df = data.frame(Statistic=adftest$statistic,P.Value=adftest$p.value,Alternative=adftest$alternative)
kable(df,row.names = F,caption = "ADF Test Results")
```

The p-value of the ADF test is $p=0.01$, this means that there is sufficient evidence to reject the null hypothesis. Thus we can conclude that the series is stationary.


## 2.4 SARIMA (Seasonal-ARIMA) Models

Section 2.1 presented the shortcomings of applying non-seasonal models to the series as they failed to provide a good fit to the series and produced inaccurate forecasts. The focus is now on $SARIMA(p,d,q)(P,D,Q)[M]$ seasonal models. By adding seasonal components $(P,D,Q)[M]$ to the already existing $ARIMA(p,d,q)$ model framework, we aim to capture the seasonality present in the data which should enable the development of more robust/accurate forecasts. The orders of $p,d,q,P,D,Q$ were selected using the ACF and PACF plots in Section 2.0.2.

### 2.4.1 SARIMA(4,1,4)(2,1,1)[7]

The spikes at lag 7 and lag 14 in the PACF plot in Figure 8 suggest that if we choose $m=7$ then we start with $P=2$ for the seasonal AR component as the initial candidate model. The ACF plot in Figure 8 suggests $Q=1$ for the seasonal MA component due to the significant spike at lag 7. The significant spikes at lag 4 in the ACF/PACF of Figure 8 suggest that $p=4$ and $q=4$ be used as the non-seasonal AR and MA components.

```{r}
#SARIMA Models

# sarima_models=train|>model(
#                                    `SARIMA(4,1,4)(2,1,1)[7]`=ARIMA(peak_demand ~1+pdq(4,1,4)+PDQ(2,1,1,period=7)),
#                                   `SARIMA(4,1,4)(2,1,1)[7]+Fourier(365)`=ARIMA(peak_demand ~1+pdq(7,1,7)+PDQ(2,1,1,period=7)+fourier(period=365,K=7))
                                  # )
# #
#sarima_model_365=train|>model(`SARIMA(3,0,3)(0,1,0)[365]`=ARIMA(peak_demand ~1+pdq(3,0,3)+PDQ(0,1,0,period=365)))
```

```{r,fig.height=3}
#save(sarima_models,sarima_model_365, file = "sarimas.RData")
load("sarimas.RData")

```


```{r,fig.height=3,fig.cap="SARIMA(4,1,4)(2,1,1)[7] residual plot."}
sarima_selected_model=sarima_models |> select(`SARIMA(4,1,4)(2,1,1)[7]`)
gg_tsdisplay(residuals(sarima_selected_model), plot_type='partial')

# autoplot(acf(residuals(sarima_selected_model),lag.max = 365, plot = FALSE)) +
#   labs(title = "Autocorrelation Function (ACF)",
#        x = "Lag",
#        y = "ACF") +
#   geom_hline(yintercept = 0, linetype = "solid", color = "black") +
#   scale_x_continuous(
#     breaks = c(0, 15, 30,45),  # Custom x-axis breaks
#     labels = c("0", "100","200", "300")  # Custom x-axis labels
#   ) +
#   theme_minimal()
#Checking AC in residuals
```


```{r}
lb_df=augment(sarima_selected_model)|>features(.resid, ljung_box, lag=14, dof =13)
round(lb_df[,2:3],3)|>kable(col.names = c("LB Statistic","P-value"),caption = "Ljung-Box Test Results")

```

The residuals of the $SARIMA(4,1,4)(2,1,1)[7]$ model suggest that the model is a good fit to the data as there does not appear to be any significant autocorrelation in the ACF/PACF plots. This is supported by the results of the Ljung-Box test which show $p-value>>0.05$ indicating that we fail to reject $H_0$, therefore we can conclude there is no significant autocorrelation in the residuals.

```{r,fig.height=2,fig.cap="Forecasts for SARIMA(4,1,4)(2,1,1)[7] model."}
sar_fc=sarima_selected_model|>forecast(h="92 days")
sar_fc|>autoplot(train)+xlab("Date")+ylab("Peak Demand")+ggtitle("Forecasts for SARIMA(4,1,4)(2,1,1)[7]")+xlab("Time")+ylab("Peak Demand")
sarima_norm_acc=accuracy(sar_fc$.mean,test$peak_demand)
```

Whilst the $SARIMA(4,1,4)(2,1,1)[7]$ model incorporates seasonal differencing as well as autoregressive and moving average components the forecasts suggest that the model is not a good fit. While the model appears to capture the weekly seasonality, it falls short in capturing the annual seasonality that is present in the data, thus the forecasts fail to align with what we'd expect of the forecasted values given the historical data. This suggests the need for an additional component which will model the annual pattern.

### 2.4.2 SARIMA(3,0,3)(0,1,0)[365]

An alternative approach to modelling the series is to fit another SARIMA model but set the seasonal period to $m=365$ in order to try and capture the annual seasonality that the $SARIMA(4,1,4)(2,1,1)[7]$ model failed to capture. It is noted that this will very likely affect the model's ability to capture the weekly seasonality. The choice of the $p$ and $q$ parameters arises from seasonally differencing the data with $m=365$ and then applying a further first difference which produced the ACF/PACF plots shown in the figure below.

```{r,fig.height=1.5,fig.cap="ACF/PACF of Seasonally and First Differenced data (m=365)"}
elec_demand$seas_diffed=difference(elec_demand$peak_demand,lag=365,differences=1)
elec_demand$seas_diffed=difference(elec_demand$seas_diffed,lag=1,differences=1)
acf_365=autoplot(acf(na.omit(elec_demand$seas_diffed), plot = FALSE)) +
  labs(
       x = "Lag",
       y = "ACF") +
    geom_hline(yintercept = 0, linetype = "solid", color = "black")

pacf_365=autoplot(pacf(na.omit(elec_demand$seas_diffed), plot = FALSE)) +
  labs(
       x = "Lag",
       y = "PACF") +
    geom_hline(yintercept = 0, linetype = "solid", color = "black")

grid_365 = acf_365 | pacf_365
grid_365
```


The ACF/PACF plots above suggest the $p=7$ and $q=7$, however, due to the high computational complexity of fitting this model with a $m=365$, $p=3$ and $q=3$ are chosen as the orders for model. The model fit to the series is specified as a $SARIMA(3,0,3)(0,1,0)[365]$.


```{r,fig.height=3,fig.cap="SARIMA(3,0,3)(0,1,0)[365] residual plot."}
sarima_selected_model=sarima_model_365 |> select(`SARIMA(3,0,3)(0,1,0)[365]`)
gg_tsdisplay(residuals(sarima_selected_model), plot_type='partial')
```


```{r}
#Checking AC in residuals
lb_df=augment(sarima_selected_model)|>features(.resid, ljung_box, lag=14, dof =8)

round(lb_df[,2:3],3)|>kable(col.names = c("LB Statistic","P-value"),caption = "Ljung-Box Test Results")

```

The significant autocorrelation at lags 2,3,4,7 in the ACF and PACF plots of the residuals suggest that the model is an inadequate fit to the data and that there is information in the series that the model has failed to capture. It is clear that by neglecting the weekly seasonality by choosing $m=365$ the model has failed to capture the weekly seasonality which can be seen by the spikes in autocorrelation in the ACF and PACF at lags that are a multiple of 7.


```{r,fig.height=2}
sar_fc=sarima_selected_model|>forecast(h="92 days")
sar_fc|>autoplot(train)+ggtitle("Forecasts for SARIMA(3,0,3)(0,1,0)[365]")+xlab("Time")+ylab("Peak Demand")
sarima_365_acc=accuracy(sar_fc$.mean,test$peak_demand)
```

The forecasts for this represent the annual pattern in the series fairly well as they don't just fluctuate around a constant mean but seem to follow the patterns seen in the historical data, however, the strong autocorrelation present in the residuals at lag 7 make it clear that this model is not appropriate for the series. So whilst the forecasts appear more promising than the $SARIMA(4,1,4)(2,1,1)[7]$ model, further model fitting and exploration is required to find a model that can account for multiple/complex seasonalities.

### 2.4.3 SARIMA(4,1,4)(2,1,1)[7]+Fourier(365)

A possible solution to handling a series with complex/multiple seasonality is fitting a dynamic harmonic regression model with an ARIMA error structure (*REF*).
Put simply, Fourier terms are added to a SARIMA model to account for some one of more of the seasonalities in the data.Therefore, the $SARIMA(4,1,4)(2,1,2)[7]+Fourier(p=365,k=7)$ model is proposed (where $p$ is the period of the Fourier term and $k$ is the order of fourier terms). This specification uses the Fourier terms to try capture the annual seasonality in the data as the period of the annual seasonality is estimated to be 365 days, $k$ is chosen to be 7 as this allows for a more flexible fit which will help avoid underfitting.

```{r,fig.height=3,fig.cap="SARIMA(4,1,4)(2,1,1)[7]+Fourier(365) residual plot."}
sarima_selected_model=sarima_models |> select(`SARIMA(4,1,4)(2,1,1)[7]+Fourier(365)`)
gg_tsdisplay(residuals(sarima_selected_model), plot_type='partial')

```


```{r}
#Checking AC in residuals
lb_df=augment(sarima_selected_model)|>features(.resid, ljung_box, lag=14, dof =6)
round(lb_df[,2:3],3)|>kable(col.names = c("LB Statistic","P-value"),caption = "Ljung-Box Test Results")
```

The residuals for the $SARIMA(4,1,4)(2,1,1)[7]+Fourier(p=365,k=7)$ model suggest that the model is a good fit to the data as there is no significant autocorrelation shown in the ACF or PACF plots. This is supported by the results of the Ljung-Box test for which the $p-value = 0.119$ which as per the hypotheses stated in Section 2.1 means that there is insignificant evidence to reject $H_0$, therefore, we can conclude there is insignificant autocorrelation in the residuals and that the model is capturing the available information in the series well.

```{r,fig.height=2}
sar_fc=sarima_selected_model|>forecast(h="92 days")
sar_fc|>autoplot(train)+xlab("Time")+ylab("Peak Demand")+ggtitle("Forecasts for SARIMA(4,1,4)(2,1,1)[7]+Fourier(p=365,k=5)")
sarima_four_acc=accuracy(sar_fc$.mean,test$peak_demand)
```

The forecasts support the claim that the model is a good fit to the data as the model appears to capture both the weekly and annual seasonality and produce forecasts similar to what we'd expect given the historical data. The addition of the Fourier term seems to have helped capture the annual seasonal component, allowing the SARIMA component to focus on the weekly seasonality. Although it must be noted that the forecast do appear quite smooth which might indicate that the model is underfitting.

## 2.4 Benchmark Model - Seasonal Naive

Models that we build for forecasting should always be compared to a simple benchmark model as we need to be able to justify the additional complexity introduced when using a model such as an ARIMA or SARIMA model. The more complex model should significantly outperform and present improvements over the simpler forecasting model/method.

In the context of this problem, the seasonal naive forecasting method presents itself as the most appropriate benchmark method for forecasting the series due to the presence of strong seasonality in the series. 

```{r,fig.height=2}
SeasonalNaive= train|>model(SNAIVE(peak_demand ~ lag("year")))
SN_fc=SeasonalNaive|>forecast(h="92 days")
SN_fc|>autoplot(train)+xlab("Time")+ylab("Peak Demand")+ggtitle("Forecasts for Seasonal Naive Method")
benchmark_residuals = SN_fc$.mean - test$peak_demand
sn_acc =  accuracy(SN_fc$.mean,test$peak_demand)
```

The forecasts produced by the Seasonal Naive model appear to be accurate and represent both the weekly and annual seasonalities present in the series. The accuracy of the forecasts will be compared to the other models in Section 2.7 in which the quality of the Seasonal Naive forecasts will then be determined.

## 2.5 ARCH and GARCH models

### 2.5.1 ARCH
```{r,fig.cap="Time and ACF plots of returns/squared returns."}
elec_demand_df=as.data.frame(elec_demand[,-c(3,4)])
elec_demand_df$Date=as.Date(elec_demand_df$Date)
elec_demand_df=elec_demand_df|>filter(Date>="2023-01-01")

elec_xts = xts(elec_demand_df$peak_demand,order.by=elec_demand_df$Date)
log_daily_returns = dailyReturn(elec_xts,type="log")

log_returns_plot = log_daily_returns|>autoplot()+ggtitle("Log Daily Returns")
log_returns_squared_plot = (log_daily_returns^2)|>autoplot()+ggtitle("Squared Log Daily Returns")
log_returns_acf=autoplot(acf(log_daily_returns, plot = FALSE)) +
  labs(title = "Log Daily Returns - ACF",
       x = "Lag",
       y = "ACF") +
    geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  theme_minimal()

log_returns_squared_acf=autoplot(acf((log_daily_returns^2), plot = FALSE)) +
  labs(title = "Squared Log Daily Returns - ACF",
       x = "Lag",
       y = "ACF") +
    geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  theme_minimal()

rets_grid = (log_returns_plot|log_returns_squared_plot)/(log_returns_acf|log_returns_squared_acf)
rets_grid

```




```{r}
spec_arch1=ugarchspec(variance.model=list(model="sGARCH", garchOrder=c(1,0)),mean.model=list(armaOrder=c(7,7),include.mean=T))
arch1=ugarchfit(spec = spec_arch1, data=log_daily_returns)

spec_arch2=ugarchspec(variance.model=list(model="sGARCH", garchOrder=c(2,0)),mean.model=list(armaOrder=c(14,14),include.mean=T))
arch2=ugarchfit(spec = spec_arch2, data=log_daily_returns)

par(mfrow=c(2,2))
plot(arch1,which=10)
plot(arch1,which=1)
plot(arch2,which=10)
plot(arch2,which=1)
```

### 2.5.2 GARCH

```{r}
spec_garch11=ugarchspec(variance.model=list(model="sGARCH", garchOrder=c(1,1)),mean.model=list(armaOrder=c(7,7),include.mean=T))
garch11=ugarchfit(spec = spec_garch11, data=log_daily_returns)

spec_garch21=ugarchspec(variance.model=list(model="sGARCH", garchOrder=c(2,1)),mean.model=list(armaOrder=c(7,7),include.mean=T))
garch21=ugarchfit(spec = spec_garch21, data=log_daily_returns)

spec_garch22=ugarchspec(variance.model=list(model="sGARCH", garchOrder=c(2,2)),mean.model=list(armaOrder=c(7,7),include.mean=T))
garch22=ugarchfit(spec = spec_garch22, data=log_daily_returns)

par(mfrow=c(3,2))
plot(garch11,which=10)
plot(garch11,which=1)

plot(garch21,which=10)
plot(garch21,which=1)

plot(garch22,which=10)
plot(garch22,which=1)

```


## 2.7 Eskom's Forecasts

The residuals for the forecasts made by Eskom appear to be stationary, however, they show that there is strong autocorrelation at lag 1 which suggests that the model that they fit/method they use to produce the forecasts has failed to capture all of the information available in the data and that observations 1 time period (day in this case) apart are highly correlated. We cannot perform a Ljung-Box test as the model which Eskom used to produce these forecasts is not specified, however, the presence of autocorrelation in the residuals is clear. 

```{r,fig.height=3}
residuals_ts = data.frame(Date=esk_forecasts$Date,Residuals=esk_forecasts$RSA.Contracted.Forecast-elec_demand$peak_demand)|>as_tsibble(index=Date)

gg_tsdisplay(residuals_ts,plot_type = "partial")
```

The forecasts made by Eskom are in line with what we'd expect from the series.

```{r,fig.height=2}
esk_forecasts_last_3 = esk_forecasts|>filter(Date>="2023/06/14")
esk_acc = accuracy(esk_forecasts_last_3$RSA.Contracted.Forecast,test$peak_demand)


autoplot(train,peak_demand)+autolayer(esk_forecasts_last_3,RSA.Contracted.Forecast,color="red")+ggtitle("Forecasts made by Eskom")+xlab("Time")+ylab("Peak Demand")
```

## 2.8 Comparing Forecasting models/methods

```{r}
accs = as.data.frame(rbind(ar_acc,ma_acc,arma_acc,arima_acc,sarima_norm_acc,sarima_365_acc,sarima_four_acc,sn_acc,esk_acc))
rownames(accs)=c("AR(8)","MA(7)","ARMA(5,6)","ARIMA(5,1,4)","SARIMA(4,1,4)(2,1,1)[7]","SARIMA(3,0,3)(0,1,0)[365]","SARIMA(4,1,4)(2,1,1)[7]+Fourier(365)","Seasonal Naive","Eskom's Forecasts")
kable(round(accs,3)[,c(2,3)],caption="Forecasting accuracies of models/methods")
```
The forecasted values for the peak demand of electricity were then used to calculate the accuracy of the forecasts by comparing them to the observed demand values in the test set. The table above shows various accuracy metrics for the forecasts produced using AR, MA, ARMA, ARIMA and SARIMA models as well as the Seasonal Naive forecasting method and the forecasts provided by Eskom.

The findings in Table X and Section 2.2 allow for the non-seasonal models to be ruled out of contention, due to poor model fit and forecast quality/accuracy.

The residuals for the $SARIMA(4,1,4)(2,1,1)[7]$ showed good model fit based on the residual analysis in Section 2.4.1, however, the forecast accuracy was lacking as the model struggled to capture the annual seasonality.

The $SARIMA(3,0,3)(0,1,0)[365]$ model had the best forecast accuracy on the test set,however, there was significant autocorrelation present in the residuals as found in Section 2.4.2 make it unreliable as there is clearly information that was not captured by the model. The performance on a single test set does not determine that the model generalizes well to all cases.

The most promising model was the $SARIMA(4,1,4)(2,1,1)[7]+Fourier(365)$ model. The residual analysis in Section 2.4.3 suggested that the model was a good fit and the forecasts aligned well with what we'd expect to see based on the historical data from the series. The forecast accuracy was also relatively good and could be improved through further tweaking of the model parameters.

The Seasonal Naive forecasting method performed very well on the test set, however, the simplicity of this method could result in poor generalization to other test sets and more rigorous testing such as Cross-Validation would be necessary to determine the general performance of this method.

Eskom's forecasts showed excellent accuracy, however, the presence of significant autocorrelation at lag 1 as discovered in the residual analysis in 2.7, suggests that whatever model/method was used to produce these forecasts failed to capture all of the available information. This might prove to be a problem in the long term for providing accurate and robust forecasts.

To produce robust forecasts, the $SARIMA(4,1,4)(2,1,1)[7]+Fourier(365)$ model should be fine-tuned to improve its forecast accuracy. If it turns out that the seasonal naive method consistently outperforms the optimized $SARIMA(4,1,4)(2,1,1)[7]+Fourier(365)$ model, even after rigorous testing, then the seasonal naive method could be preffered due to its simplicity, interpretability and it's relatively low computational complexity for creating forecasts.



# Conclusion 

\*Could investigate if water supply correlates with unplanned outages